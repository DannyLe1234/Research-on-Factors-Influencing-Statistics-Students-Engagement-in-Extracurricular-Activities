---
title: "sta304_analysis"
output: html_document
date: "2024-11-06"
---

###loading the dataset

```{r}
# Change the directory to where the dataset is stored when running the code
library(readr)
data <- read_csv("/Users/phamhieu/Desktop/UTM COURSES/STA'S/STA304/Project/survey_respond_clnd.csv")
```

### Presentation of Data and Statistical Analysis

```{r}
#Sample Size Calculation - Simple Random Sampling
library(dplyr)
library(broom)
library(flextable)

N <- 121
B = 0.05
D = (B^2)/4
  
#filter out students that participates in any extracurricular activities and  dont work
student_extra_wrk <- nrow(subset(data, activities_status == 1 & work_time != 0))

#proportion of students that participates in any extracurricular activities and work,assume p=0.5 
p <- 0.5
q <- 1-p

#sample size calculation for p
n <- ceiling((N*p*q)/((N-1)*D+p*q))

#Drawing Simple Random Samples 

#Sample 1 - Set a sample seed so that it saves the sample data
set.seed(002)
sample_data1 <- sample_n(data,n)
head(sample_data1)

#Two Sample Proportion Test between activity status and work time
contingency_table <- table(sample_data1$activities_status, sample_data1$work_time2)
print(contingency_table)
prop.test(contingency_table) 
prop_test_sum <- tidy(prop.test(contingency_table))
prop_test1_table <- flextable(prop_test_sum) %>%
  set_caption(caption = "Two Sample Proportion Test between Activity Status and Work Time")%>%
  autofit()%>%
  theme_vanilla()
print(prop_test1_table)

#fail to reject Null hypotheis


```

```{r}
#Sample Size Calculation - Simple Random Sampling
library(dplyr)
library(broom)
library(flextable)
  
#Drawing Simple Random Samples 

#Sample 2 - Set a sample seed so that it saves the sample data
set.seed(212)
sample_data2 <- sample_n(data,n)
head(sample_data2)


#Two Sample Proportion Test between activity status and study time
contingency_table2 <- table(sample_data2$activities_status, sample_data2$study_time2)
print(contingency_table2)
prop.test(contingency_table2)

prop_test_sum <- tidy(prop.test(contingency_table2))
prop_test2_table <- flextable(prop_test_sum) %>%
  set_caption(caption = "Two Sample Proportion Test between Activity Status and Study Time")%>%
  autofit()%>%
  theme_vanilla()

print(prop_test2_table)

#fail to reject null hypothesis

#conclude: RQ2 can't conlude that studytime and worktime affect activities status
```

### Simple Test 1 - Simple Linear Regression (Failed gotta do another one T.T)

```{r}

#Response Variable
barplot(table(data$activities_status), main="Bar plot of Activities Status",
        xlab = "Activities Status", ylab = "Frequency",border =NA,col = c("#FF6666","#6699FF"))

#box plot 
data2 <- data.frame(activities_status = data$activities_status, study_time = data$study_time)
boxplot(activities_status ~ study_time, data = data2, main = "Boxplot of Activities Status by Sutdy Time Scale",xlab = "study_time", ylab = "Activities Status", col = "cadetblue")

#box plot2
data3 <- data.frame(activities_status = data$activities_status, necessity_scale = data$necessity_scale)
boxplot(activities_status ~ necessity_scale, data = data3, main = "Boxplot of Activities Status by Necessity Scale",xlab = "necessity_scale", ylab = "Activities Status", col = "cadetblue")


```

### Advanced Test: Logistic Regression

```{r}
#No Multicolinearity

#Matrix of potential predictors
plot(data[,c("study_time","supportiveness","work_time","necessity_scale")],col="cadetblue")  

#VIF factors for each predictor

library(broom)
library(car)
model_log0 = glm(activities_status ~ study_time + supportiveness + work_time + necessity_scale, data = data, family = "binomial")
vif_value <- vif(model_log0)
vif_df <- tidy(vif_value)

library(flextable)
vif_table <- flextable(vif_df) %>%
  set_caption(caption = "VIF Values for each Predictor")%>%
  autofit()%>%
  theme_vanilla()

print(vif_table)

#Conclusion since all VIF values almost equal to 1, no correlation between any predictor

```

```{r}
#Logistic Regression on activity status and necessity scale
model_log = glm(activities_status ~  necessity_scale, data = data, family = "binomial")
summary(model_log)
library(broom)
library(flextable)
model_log_sumry <- tidy(model_log)
logreg_table <- flextable(model_log_sumry) %>%
  set_caption(caption = "Logistic Regression between Activity Status and Necessity Scale")%>%
  autofit()%>%
  theme_vanilla()

print(logreg_table)

#Logistic Regression Curve

newdata <- data.frame(necessity_scale = seq(1,5,1))
newdata$prob <- predict(model_log, newdata, type = "response")
plot(activities_status~necessity_scale, data = data, col = "blue",main ="Logistic Regression Curve between Activity Status and Necessity Scale", 
     xlab = "Necessity Scale", ylab = "Activity Status") 
lines(prob~necessity_scale, data = newdata, col = "red")


#model coefficients
coef_intercept = as.numeric(coefficients(model_log)[1])
necessity_scale_coef = as.numeric(coefficients(model_log)[2])

#probability across necessity scale

#necessity scale = 1
odds = exp(coef_intercept+necessity_scale_coef*1)
probs = odds/(1+odds)
probs

#necessity scale = 2
odds = exp(coef_intercept+necessity_scale_coef*2)
probs = odds/(1+odds)
probs

#necessity scale = 3
odds = exp(coef_intercept+necessity_scale_coef*3)
probs = odds/(1+odds)
probs

#necessity scale = 4
odds = exp(coef_intercept+necessity_scale_coef*4)
probs = odds/(1+odds)
probs

#necessity scale = 5
odds = exp(coef_intercept+necessity_scale_coef*5)
probs = odds/(1+odds)
probs
```


```{r}
#Probability of participating in extracurricular activities given necessity scale

# Logistic Regression on activity status and supportiveness
model_log2 = glm(activities_status ~ supportiveness2, data = data, family = "binomial")
summary(model_log2)
library(broom)
library(flextable)
model_log2_sumry <- tidy(model_log2)
logreg_table2 <- flextable(model_log2_sumry) %>%
  set_caption(caption = "Logistic Regression between Activity Status and Supportiveness")%>%
  autofit()%>%
  theme_vanilla()

print(logreg_table2)

#Plotting the Logistic Regression Curve
library(ggplot2)
# Generate predicted probabilities
new_data <- data.frame(supportiveness2 = seq(0, 1,1))
new_data$predicted_probs <- predict(model_log2, newdata = new_data, type = "response")

ggplot(new_data, aes(x = supportiveness2, y = predicted_probs)) +
  geom_line(color = "blue", size = 1.2) + 
  geom_point(data = data, aes(x = supportiveness2, y = activities_status), color = "red") +  
  labs(title = "Logistic Regression Curve: Activity Status vs Supportiveness",x = "Supportiveness (0 = No Support, 1 = Support)",y = "Predicted Probability of Participation") +theme_minimal()

#model coefficients
coef_intercept = as.numeric(coefficients(model_log2)[1])
supportiveness_scale = as.numeric(coefficients(model_log2)[2])
coef_intercept
supportiveness_scale

#Probability across all supportiveness levels

#supportiveness = 0
odds = exp(coef_intercept+supportiveness_scale*0)
probs = odds/(1+odds)
probs

#supportiveness = 1
odds = exp(coef_intercept+supportiveness_scale*1)
probs = odds/(1+odds)
probs

```

```{r}
library(broom)
library(flextable)
model_log3 = glm(activities_status ~ supportiveness_category + necessity_scale, data = data, family = "binomial")
summary(model_log3)
model_log3_sumry <- tidy(model_log3)
mltpl_logreg_table <- flextable(model_log3_sumry) %>%
  set_caption(caption = "Logistic Regression between Activity Status versus Supportiveness and Necessity Scale")%>%
  autofit() %>%
  theme_vanilla()

print(mltpl_logreg_table)

#Plotting the Multiple Logistic Regression Curve


library(ggplot2)

new_data <- expand.grid(necessity_scale = seq(1,5,1),supportiveness_category = unique(data$supportiveness_category))
new_data$predicted_probs <- predict(model_log3, newdata = new_data, type = "response")
ggplot(new_data, aes(x = necessity_scale, y = predicted_probs, color = supportiveness_category)) +
  geom_line(size = 1) +  # Smooth logistic regression curves
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +  # Ensure y-axis is between 0 and 1
  labs(
    title = "Logistic Regression: Combined Effect of Predictors",
    x = "Necessity Scale",
    y = "Predicted Probability of Participation",
    color = "Supportiveness"
  ) +
  theme_minimal()



#model coefficients
coef_intercept = as.numeric(coefficients(model_log3)[1])
supportiveness_Y = as.numeric(coefficients(model_log3)[2])
necessity_scale_coef = as.numeric(coefficients(model_log3)[3])


#Probability of participating in extracurricular activities given necessity scale and supportiveness 

#If student family is supportive(Y) and necessity scale = 1
odds = exp(coef_intercept+supportiveness_Y*1+necessity_scale_coef*1)
probs = odds/(1+odds)
probs

#If student family is not supportive(N) and necessity scale = 1
odds = exp(coef_intercept+supportiveness_Y*0+necessity_scale_coef*1)
probs = odds/(1+odds)
probs

#If student family is supportive(Y) and necessity scale = 2
odds = exp(coef_intercept+supportiveness_Y*1+necessity_scale_coef*2)
probs = odds/(1+odds)
probs

#If student family is not supportive(N) and necessity scale = 2
odds = exp(coef_intercept+supportiveness_Y*0+necessity_scale_coef*2)
probs = odds/(1+odds)
probs

#If student family is supportive(Y) and necessity scale = 3
odds = exp(coef_intercept+supportiveness_Y*1+necessity_scale_coef*3)
probs = odds/(1+odds)
probs

#If student family is not supportive(N) and necessity scale = 3
odds = exp(coef_intercept+supportiveness_Y*0+necessity_scale_coef*3)
probs = odds/(1+odds)
probs

#If student family is supportive(Y) and necessity scale = 4
odds = exp(coef_intercept+supportiveness_Y*1+necessity_scale_coef*4)
probs = odds/(1+odds)
probs

#If student family is not supportive(N) and necessity scale = 4
odds = exp(coef_intercept+supportiveness_Y*0+necessity_scale_coef*4)
probs = odds/(1+odds)
probs

#If student family is supportive(Y) and necessity scale = 5
odds = exp(coef_intercept+supportiveness_Y*1+necessity_scale_coef*5)
probs = odds/(1+odds)
probs

#If student family is not supportive(N) and necessity scale = 5
odds = exp(coef_intercept+supportiveness_Y*0+necessity_scale_coef*5)
probs = odds/(1+odds)
probs

```
### Pearson's Chi Square Test
```{r}

# Create a new column that contains only the first activity
data_activities_short <- substr(sample_data2$activities, 1, 2)

# Create a contingency table for the two columns
contingency_table3<- table(sample_data2$favorite_activity,data_activities_short)
print(contingency_table3)

# Perform the chi-squared independence test
chi_squared_test <- chisq.test(contingency_table3)
chi_squared_test$expected



# Print the results
library(broom)
library(knitr)

#Chi-Square Test Result
chi_squared_test_sum <- tidy(chi_squared_test)

chi_sqr_tst_tble <- flextable(chi_squared_test_sum) %>%
  set_caption(caption = "Pearson's Chi Square Test between Favorite Activity and Activity")%>%
  autofit()%>%
  theme_vanilla()

print(chi_sqr_tst_tble)

#Frequency Table
frqncy_sum <- as.data.frame(chi_squared_test$expected)
frqncy_sum <- cbind(Activity_vs_Favorite_Activity = rownames(chi_squared_test$expected), frqncy_sum)

frqncy_table <- flextable(frqncy_sum) %>%
  set_caption(caption = "Expected Values for Pearson's Chi Square Test between Favorite Activity and Activity")%>%
  autofit()%>%
  bold(part = "header")

print(frqncy_table)

#Success to reject the Null Hypothesis
```


### Stacked bar-chart to summarize the open responses 
```{r}
library(ggplot2)

# Stacked bar chart
ggplot(data, aes(x = open_reason, fill = factor(necessity_scale))) +
  geom_bar(position = "fill") +
  labs(y = "Proportion", fill = "Likert Scale") +
  theme_minimal()

library(tidyr)

summary_table <- data %>%
  group_by(open_reason, necessity_scale) %>%
  summarise(count = n()) %>%
  spread(key = necessity_scale, value = count, fill = 0)

print(summary_table)
```










